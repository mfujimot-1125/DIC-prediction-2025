{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directory Setup\n",
    "- Store the feature sets for all ICU admissions in `data_dir`.\n",
    "- Save the model outputs in `output_dir`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = \"20250420\"\n",
    "data_dir = '../data/'\n",
    "output_dir = '../output/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create DataFrame\n",
    "- Load the CSV file, perform random sampling of `laboratory_measurements`, and convert it into a unique DataFrame based on `icu_stay_id` and `time_window`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dic_prediction_all = pd.read_csv(os.path.join(data_dir, date, f'{date}.csv'))\n",
    "df_dic_prediction_all[\"icu_stay_id\"] = df_dic_prediction_all[\"icu_stay_id\"].astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7532"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confirm number of total unique ids\n",
    "len(df_dic_prediction_all['icu_stay_id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Random Sampling of Laboratory Measurements\n",
    "Only the laboratory measurements are retrieved without aggregation within a specified time series interval.\n",
    "Group the data by `icu_stay_id` and `time_window_index`, and randomly select one record from each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_select_from_time_window(group: pd.DataFrame) -> pd.DataFrame:\n",
    "    return group.groupby(['icu_stay_id', 'time_window_index']).apply(lambda x: x.sample(n=1, random_state=42)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mw/7366jqyd24db0gsndhcd1cl00000gn/T/ipykernel_61331/2246292326.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return group.groupby(['icu_stay_id', 'time_window_index']).apply(lambda x: x.sample(n=1, random_state=42)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "df_dic_sampled = random_select_from_time_window(df_dic_prediction_all)\n",
    "df_dic_sampled = df_dic_sampled.where(pd.notnull(df_dic_sampled), None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Retrieve Variables used for models from the Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv(os.path.join(data_dir,'featureset.csv'))\n",
    "\n",
    "ids_and_variables_for_statistics = [ 'icu_stay_id', 'hospital_id', 'in_time', 'out_time', 'start_time', 'end_time',\n",
    "                                    'label_dic_diagnosis', 'isth_dic_score', 'sofa_score', 'sic_score', 'body_weight']\n",
    "\n",
    "# retrieve variables for 'minimum model', 'compact model', 'full model' \n",
    "minimum_model_features = features[features['minimum model'] == 1]['Feature'].tolist()\n",
    "compact_model_features = features[features['compact model'] == 1]['Feature'].tolist()\n",
    "full_model_features = features[features['full model'] == 1]['Feature'].tolist()\n",
    "\n",
    "minimum_model_columns_all = ids_and_variables_for_statistics + minimum_model_features\n",
    "compact_model_columns_all = ids_and_variables_for_statistics + compact_model_features\n",
    "full_model_columns_all = ids_and_variables_for_statistics + full_model_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Stratification => Fix `training_id` and `test_id`\n",
    "- Stratification is performed so that the proportion of data with `label=1` within a specific `time_window_index` is approximately equal between the train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_df(df: pd.DataFrame, dic_flag: int, tw: int):\n",
    "    # Group by `icu_stay_id` and retrieve the data where the maximum `time_window_index` equals `tw`\n",
    "    filtered_tw = df[df.groupby('icu_stay_id')['time_window_index'].transform('max') == tw]\n",
    "    # Retrieve the data where `tw` is the maximum value and the label matches `dic_flag`\n",
    "    filtered_dic = filtered_tw[(filtered_tw['label_dic_diagnosis']==dic_flag) & (filtered_tw['time_window_index']==tw)]  \n",
    "    return filtered_dic.reset_index(drop=True)\n",
    "\n",
    "def split_on_patients(df: pd.DataFrame) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    unique_ids = df['icu_stay_id'].unique()\n",
    "    # Split the unique icu_stay_id into train and test sets\n",
    "    train_ids, test_ids = train_test_split(unique_ids, test_size=0.2, random_state=710)\n",
    "    return train_ids, test_ids\n",
    "\n",
    "def stratification(df: pd.DataFrame) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    train_ids = []\n",
    "    test_ids = []\n",
    "    for i in range(df['time_window_index'].max()+1):\n",
    "        dic = extract_df(df,1,i)\n",
    "        non_dic = extract_df(df,0,i)\n",
    "        dic_train_ids,dic_test_ids = split_on_patients(dic)\n",
    "        nondic_train_ids,nondic_test_ids = split_on_patients(non_dic)\n",
    "        train_ids = train_ids + dic_train_ids.tolist() + nondic_train_ids.tolist()\n",
    "        test_ids = test_ids + dic_test_ids.tolist() + nondic_test_ids.tolist()\n",
    "        \n",
    "    return train_ids,test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids,test_ids = stratification(df_dic_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tw=0 instances dic/all train: 300/6020=0.0498 | test: 76/1512=0.0503\n",
      "tw=1 instances dic/all train: 120/4440=0.0270 | test: 30/1116=0.0269\n",
      "tw=2 instances dic/all train: 68/3620=0.0188 | test: 17/911=0.0187\n",
      "tw=3 instances dic/all train: 54/3012=0.0179 | test: 14/759=0.0184\n",
      "tw=4 instances dic/all train: 34/2532=0.0134 | test: 9/638=0.0141\n",
      "tw=5 instances dic/all train: 21/2154=0.0097 | test: 6/542=0.0111\n",
      "tw=6 instances dic/all train: 13/1849=0.0070 | test: 4/464=0.0086\n"
     ]
    }
   ],
   "source": [
    "#Check for stratification\n",
    "train_df = df_dic_sampled[df_dic_sampled['icu_stay_id'].isin(train_ids)]\n",
    "test_df = df_dic_sampled[df_dic_sampled['icu_stay_id'].isin(test_ids)]\n",
    "\n",
    "def check_stratification(train_df, test_df):\n",
    "    for i in range(7):\n",
    "        print(f\"tw={i} instances dic/all train: {len(train_df[(train_df['time_window_index'] == i) & (train_df['label_dic_diagnosis'] == 1)])}/{len(train_df[train_df['time_window_index'] == i])}={len(train_df[(train_df['time_window_index'] == i) & (train_df['label_dic_diagnosis'] == 1)]) / len(train_df[train_df['time_window_index'] == i]):.4f} | test: {len(test_df[(test_df['time_window_index'] == i) & (test_df['label_dic_diagnosis'] == 1)])}/{len(test_df[test_df['time_window_index'] == i])}={len(test_df[(test_df['time_window_index'] == i) & (test_df['label_dic_diagnosis'] == 1)]) / len(test_df[test_df['time_window_index'] == i]):.4f}\")\n",
    "\n",
    "check_stratification(train_df,test_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.Column name conversion for output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_mapping = {\n",
    "    'female': 'Female',\n",
    "    'height': 'Height',\n",
    "    'age': 'Age',\n",
    "    'time_window_index': 'Time window index',\n",
    "    'infected_nervous_system': 'Nervous system infection',\n",
    "    'infected_cardiovascular': 'Cardiovascular infection',\n",
    "    'infected_respiratory': 'Respiratory infection',\n",
    "    'infected_abdomen': 'Abdominal infection',\n",
    "    'infected_urinary_tract': 'Urinary tract infection',\n",
    "    'infected_soft_tissue': 'Soft tissue infection',\n",
    "    'infected_other': 'Other infection',\n",
    "    'charlson_comorbidity_index': 'Charlson comorbidity index',\n",
    "    'congestive_heart_failure': 'Congestive heart failure',\n",
    "    'chronic_pulmonary_disease': 'Chronic pulmonary disease',\n",
    "    'mild_liver_disease': 'Mild liver disease',\n",
    "    'severe_liver_disease': 'Severe liver disease',\n",
    "    'diabetes_without_cc': 'Diabetes without chronic complication',\n",
    "    'diabetes_with_cc': 'Diabetes with chronic complication',\n",
    "    'renal_disease': 'Renal disease',\n",
    "    'malignant_cancer': 'Malignancy',\n",
    "    'metastatic_solid_tumor': 'Metastatic solid tumor',\n",
    "    'ph': 'pH',\n",
    "    'base_excess': 'Base excess',\n",
    "    'lactate': 'Lactate',\n",
    "    'glucose': 'Glucose',\n",
    "    'wbc': 'WBC',\n",
    "    'hemoglobin': 'Hemoglobin',\n",
    "    'platelet': 'Platelet',\n",
    "    'creatinine': 'Creatinine',\n",
    "    'total_bilirubin': 'Total bilirubin',\n",
    "    'crp': 'CRP',\n",
    "    'albumin': 'Albumin',\n",
    "    'aptt': 'APTT',\n",
    "    'ptinr': 'PT-INR',\n",
    "    'd_dimer': 'D-dimer',\n",
    "    'fibrinogen': 'Fibrinogen',\n",
    "    'fdp': 'FDP',\n",
    "    'pfratio': 'PaO2/FiO2 ratio',\n",
    "    'bt50': 'BT (median)',\n",
    "    'bt90': 'BT (90 percentile)',\n",
    "    'hr10': 'HR (10 percentile)',\n",
    "    'hr50': 'HR (median)',\n",
    "    'hr90': 'HR (90 percentile)',\n",
    "    'hr_sd': 'HR (sd)',\n",
    "    'rr10': 'RR (10 percentile)',\n",
    "    'rr50': 'RR (median)',\n",
    "    'rr90': 'RR (90 percentile)',\n",
    "    'rr_sd': 'RR (sd)',\n",
    "    'sbp10': 'SBP (10 percentile)',\n",
    "    'sbp50': 'SBP (median)',\n",
    "    'sbp90': 'SBP (90 percentile)',\n",
    "    'sbp_sd': 'SBP (sd)',\n",
    "    'mbp10': 'MBP (10 percentile)',\n",
    "    'mbp50': 'MBP (median)',\n",
    "    'mbp90': 'MBP (90 percentile)',\n",
    "    'mbp_sd': 'MBP (sd)',\n",
    "    'dbp10': 'DBP (10 percentile)',\n",
    "    'dbp50': 'DBP (median)',\n",
    "    'dbp90': 'DBP (90 percentile)',\n",
    "    'dbp_sd': 'DBP (sd)',\n",
    "    'spo2_10': 'SpO2 (10 percentile)',\n",
    "    'spo2_50': 'SpO2 (median)',\n",
    "    'spo2_90': 'SpO2 (90 percentile)',\n",
    "    'spo2_sd': 'SpO2 (sd)',\n",
    "    'urine_output_rate': 'Urine output (rate)',\n",
    "    'infusion_rate': 'Infusion (rate)',\n",
    "    'gcs_e': 'GCS (E)',\n",
    "    'gcs_v': 'GCS (V)',\n",
    "    'gcs_m': 'GCS (M)',\n",
    "    'adrenaline': 'Adrenaline (rate)',\n",
    "    'noradrenaline': 'Noradrenaline (rate)',\n",
    "    'vasopressin': 'Vasopressin (rate)'\n",
    "}\n",
    "\n",
    "def update_column_names(df):\n",
    "    new_columns = [column_mapping.get(col, col) for col in df.columns]\n",
    "    df.columns = new_columns\n",
    "    return df\n",
    "\n",
    "derivation_model1 = update_column_names(df_dic_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "derivation_model1.to_csv(os.path.join(data_dir, date, f'{date}_derivation_model1.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-1 Check the Condition of the Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int64_columns_1 = [col for col in derivation_model1.columns if derivation_model1[col].dtype == 'int64']\n",
    "int64_columns_1.remove(\"icu_stay_id\")\n",
    "derivation_model1[int64_columns_1] = derivation_model1[int64_columns_1].astype('int32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float64_columns_1 = [col for col in derivation_model1.columns if derivation_model1[col].dtype == 'float64']\n",
    "derivation_model1[float64_columns_1] = derivation_model1[float64_columns_1].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resolve fragmentation by copying\n",
    "derivation_model1 = derivation_model1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_model1 = derivation_model1[derivation_model1['icu_stay_id'].isin(train_ids)].rename(columns={'label_dic_diagnosis':'y'})\n",
    "test_df_model1 = derivation_model1[derivation_model1['icu_stay_id'].isin(test_ids)].rename(columns={'label_dic_diagnosis':'y'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the data of `icu_stay_id` that has taken the value y=1 (DIC onset) at least once\n",
    "dic_train = train_df_model1[train_df_model1.groupby('icu_stay_id')['y'].transform('max') == 1]\n",
    "dic_test = test_df_model1[test_df_model1.groupby('icu_stay_id')['y'].transform('max') == 1]\n",
    "# Extract the data of `icu_stay_id` that has never taken the value y=1 (no DIC onset)\n",
    "nondic_train = train_df_model1[train_df_model1.groupby('icu_stay_id')['y'].transform('max') == 0]\n",
    "nondic_test = test_df_model1[test_df_model1.groupby('icu_stay_id')['y'].transform('max') == 0]\n",
    "# Merge the data respectively\n",
    "dic_df_model1 = pd.concat([dic_train, dic_test])\n",
    "nondic_df_model1 = pd.concat([nondic_train, nondic_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---model1 DIC---\n",
      "Training(ids):  610   Test(ids):  156\n",
      "---model1 non DIC---\n",
      "Training(ids):  5410   Test(ids):  1356\n"
     ]
    }
   ],
   "source": [
    "#check the number of dic and non-dic unique ids \n",
    "print(\"---model1 DIC---\")\n",
    "print(\"Training(ids): \",len(train_df_model1[train_df_model1['y'] == 1]['icu_stay_id'].unique()), \"  Test(ids): \",len(test_df_model1[test_df_model1['y'] == 1]['icu_stay_id'].unique()))\n",
    "print(\"---model1 non DIC---\")\n",
    "print(\"Training(ids): \",len(train_df_model1.groupby('icu_stay_id')['y'].max()[train_df_model1.groupby('icu_stay_id')['y'].max() == 0].index), \"  Test(ids): \",len(test_df_model1.groupby('icu_stay_id')['y'].max()[test_df_model1.groupby('icu_stay_id')['y'].max() == 0].index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as csv\n",
    "train_df_model1.to_csv(os.path.join(data_dir, date,f'{date}_train_df_model1.csv'))\n",
    "test_df_model1.to_csv(os.path.join(data_dir, date, f'{date}_test_df_model1.csv'))\n",
    "dic_df_model1.to_csv(os.path.join(data_dir, date,f'{date}_dic_df_model1.csv'))\n",
    "nondic_df_model1.to_csv(os.path.join(data_dir, date, f'{date}_nondic_df_model1.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
